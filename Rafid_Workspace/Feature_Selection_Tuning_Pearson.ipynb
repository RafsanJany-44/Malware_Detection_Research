{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d802187-e16b-46e0-911b-6736f4cf7dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "\n",
    "\n",
    "def pearson(X,y,num_of_feat):\n",
    "  fs = SelectKBest(score_func=f_regression, k=5)\n",
    "  fit = fs.fit(X,y)\n",
    "\n",
    "  dfscores = pd.DataFrame(fit.scores_)\n",
    "  dfcolumns = pd.DataFrame(df.columns)\n",
    "  featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "  featureScores.columns = ['Best_columns','Score_pearsons']\n",
    "\n",
    "  lyst = featureScores.nlargest(num_of_feat,'Score_pearsons')\n",
    "\n",
    "  PEARSON_feature=list(lyst['Best_columns'])\n",
    "  return PEARSON_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8bffade-5968-4be1-acd9-76ed1b742f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"permission-based_malware.csv\") \n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[: , df.columns!=target] \n",
    "X = X.loc[: , X.columns!=\"NAME\"]\n",
    "y = df[target] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e647f3-e003-461b-9399-e3d57f144913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of column:  50\n",
      "Testing Accurecy:  0.6923076923076923\n",
      "Training Accurecy:  0.684154175588865\n",
      "___________________________________________________________________________________________\n",
      "Number of column:  100\n",
      "Testing Accurecy:  0.7051282051282052\n",
      "Training Accurecy:  0.69593147751606\n",
      "___________________________________________________________________________________________\n",
      "Number of column:  150\n",
      "Testing Accurecy:  0.7264957264957265\n",
      "Training Accurecy:  0.7462526766595289\n",
      "___________________________________________________________________________________________\n",
      "Number of column:  200\n",
      "Testing Accurecy:  0.7863247863247863\n",
      "Training Accurecy:  0.8019271948608137\n",
      "___________________________________________________________________________________________\n",
      "Number of column:  250\n",
      "Testing Accurecy:  0.8162393162393162\n",
      "Training Accurecy:  0.8468950749464668\n",
      "___________________________________________________________________________________________\n",
      "Number of column:  300\n",
      "Testing Accurecy:  0.8333333333333334\n",
      "Training Accurecy:  0.8597430406852249\n",
      "___________________________________________________________________________________________\n",
      "Number of column:  350\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '041f8b32fa15efda620b04a5dd41554a.apk'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_27552\\3326511523.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHistGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m51\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Testing Accurecy: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1470\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1471\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1473\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1474\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0macc_apply_split_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m  \u001b[1;31m# time spent splitting nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m         \u001b[0macc_compute_hist_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m  \u001b[1;31m# time spent computing histograms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# time spent predicting X for gradient and hessians update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0macc_prediction_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknown_categories\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess_X\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_encode_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m         \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\ensemble\\_hist_gradient_boosting\\gradient_boosting.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    273\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_categorical_\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocessor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_categorical_remapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_X_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    630\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    634\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    994\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    995\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    997\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 998\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    999\u001b[0m                 raise ValueError(\n\u001b[0;32m   1000\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    517\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\nadip\\anaconda3\\envs\\Test_Environment\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2148\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m         if (\n\u001b[0;32m   2152\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2153\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '041f8b32fa15efda620b04a5dd41554a.apk'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of column: \",i)\n",
    "    pearson_list = pearson(X,y,i) \n",
    "    \n",
    "    X_ = df.loc[:,pearson_list] \n",
    "    y_ = df[target] \n",
    "    \n",
    "    from sklearn.model_selection import train_test_split \n",
    "    \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state = 0)\n",
    "    \n",
    "    hist = HistGradientBoostingClassifier(max_iter=51,max_depth=16,random_state=0)\n",
    "    hist.fit(X_train, y_train)\n",
    "    y_pred = hist.predict(X_test)\n",
    "    print(\"Testing Accurecy: \",accuracy_score(y_test,y_pred))\n",
    "    \n",
    "    hist.fit(X_train, y_train)\n",
    "    y_pred = hist.predict(X_train)\n",
    "    print(\"Training Accurecy: \",accuracy_score(y_train,y_pred))\n",
    "    print(\"___________________________________________________________________________________________\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "227c3c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  50\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9314775160599572\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  100\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9421841541755889\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  150\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9453961456102784\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  200\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.949678800856531\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  250\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9561027837259101\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  300\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9518201284796574\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  350\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9518201284796574\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  400\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9518201284796574\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  450\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9518201284796574\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  500\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9518201284796574\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  550\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9518201284796574\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  600\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9518201284796574\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  650\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9518201284796574\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  700\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9518201284796574\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  750\n",
      "Testing Accuracy:  0.9316239316239316\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  800\n",
      "Testing Accuracy:  0.9316239316239316\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  850\n",
      "Testing Accuracy:  0.9316239316239316\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  900\n",
      "Testing Accuracy:  0.9316239316239316\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def pearson(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=f_regression, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_pearsons']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_pearsons')\n",
    "\n",
    "    PEARSON_feature = list(lyst['Best_columns'])\n",
    "    return PEARSON_feature\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"permission-based_malware.csv\")\n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of columns: \", i)\n",
    "    pearson_list = pearson(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, pearson_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    hist = HistGradientBoostingClassifier(max_iter=51, max_depth=16, random_state=0)\n",
    "    hist.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = hist.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = hist.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f225127e",
   "metadata": {},
   "source": [
    "## Using Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70c11f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  50\n",
      "Testing Accuracy:  0.8846153846153846\n",
      "Training Accuracy:  0.8843683083511777\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  100\n",
      "Testing Accuracy:  0.8589743589743589\n",
      "Training Accuracy:  0.9218415417558886\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  150\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9186295503211992\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  200\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9293361884368309\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  250\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9357601713062098\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  300\n",
      "Testing Accuracy:  0.9017094017094017\n",
      "Training Accuracy:  0.9293361884368309\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  350\n",
      "Testing Accuracy:  0.9102564102564102\n",
      "Training Accuracy:  0.9389721627408993\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  400\n",
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9379014989293362\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  450\n",
      "Testing Accuracy:  0.8931623931623932\n",
      "Training Accuracy:  0.9357601713062098\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  500\n",
      "Testing Accuracy:  0.8974358974358975\n",
      "Training Accuracy:  0.9539614561027837\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  550\n",
      "Testing Accuracy:  0.9230769230769231\n",
      "Training Accuracy:  0.943254817987152\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  600\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.961456102783726\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  650\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9528907922912205\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  700\n",
      "Testing Accuracy:  0.9102564102564102\n",
      "Training Accuracy:  0.9539614561027837\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  750\n",
      "Testing Accuracy:  0.9102564102564102\n",
      "Training Accuracy:  0.9507494646680942\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  800\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9561027837259101\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  850\n",
      "Testing Accuracy:  0.9102564102564102\n",
      "Training Accuracy:  0.9582441113490364\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  900\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9593147751605996\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def mutual_info_selection(X, y, num_of_feat):\n",
    "    fs = SelectKBest(score_func=mutual_info_regression, k=num_of_feat)\n",
    "    fit = fs.fit(X, y)\n",
    "\n",
    "    dfscores = pd.DataFrame(fit.scores_)\n",
    "    dfcolumns = pd.DataFrame(X.columns)\n",
    "    featureScores = pd.concat([dfcolumns, dfscores], axis=1)\n",
    "    featureScores.columns = ['Best_columns', 'Score_mutual_info']\n",
    "\n",
    "    lyst = featureScores.nlargest(num_of_feat, 'Score_mutual_info')\n",
    "\n",
    "    mutual_info_features = list(lyst['Best_columns'])\n",
    "    return mutual_info_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"permission-based_malware.csv\")\n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of columns: \", i)\n",
    "    mutual_info_list = mutual_info_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, mutual_info_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    hist = HistGradientBoostingClassifier(max_iter=51, max_depth=16, random_state=0)\n",
    "    hist.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = hist.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = hist.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61832e4c",
   "metadata": {},
   "source": [
    "## Using Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "db6a8250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns:  50\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9164882226980728\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  100\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9400428265524625\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  150\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9421841541755889\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  200\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9411134903640257\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  250\n",
      "Testing Accuracy:  0.9188034188034188\n",
      "Training Accuracy:  0.9464668094218416\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  300\n",
      "Testing Accuracy:  0.9102564102564102\n",
      "Training Accuracy:  0.9593147751605996\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  350\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9561027837259101\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  400\n",
      "Testing Accuracy:  0.905982905982906\n",
      "Training Accuracy:  0.9561027837259101\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  450\n",
      "Testing Accuracy:  0.9273504273504274\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  500\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9625267665952891\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  550\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9625267665952891\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  600\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9625267665952891\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  650\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9625267665952891\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  700\n",
      "Testing Accuracy:  0.9145299145299145\n",
      "Training Accuracy:  0.9625267665952891\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  750\n",
      "Testing Accuracy:  0.9316239316239316\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  800\n",
      "Testing Accuracy:  0.9316239316239316\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  850\n",
      "Testing Accuracy:  0.9316239316239316\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n",
      "Number of columns:  900\n",
      "Testing Accuracy:  0.9316239316239316\n",
      "Training Accuracy:  0.9646680942184154\n",
      "___________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def rfe_selection(X, y, num_of_feat):\n",
    "    model = LogisticRegression(max_iter=1000)\n",
    "    rfe = RFE(model, n_features_to_select=num_of_feat)\n",
    "    fit = rfe.fit(X, y)\n",
    "\n",
    "    feature_ranks = pd.DataFrame(fit.ranking_, index=X.columns, columns=['Rank'])\n",
    "    selected_features = feature_ranks[feature_ranks['Rank'] == 1].index.tolist()\n",
    "    \n",
    "    return selected_features\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"permission-based_malware.csv\")\n",
    "target = \"CLASS\"\n",
    "\n",
    "X = df.loc[:, df.columns != target]\n",
    "X = X.loc[:, X.columns != \"NAME\"]\n",
    "y = df[target]\n",
    "\n",
    "# Iterate over different numbers of features\n",
    "for i in range(50, len(X.columns), 50):\n",
    "    print(\"Number of columns: \", i)\n",
    "    rfe_list = rfe_selection(X, y, i)\n",
    "\n",
    "    X_ = df.loc[:, rfe_list]\n",
    "    y_ = df[target]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2, random_state=0)\n",
    "\n",
    "    hist = HistGradientBoostingClassifier(max_iter=51, max_depth=16, random_state=0)\n",
    "    hist.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred_test = hist.predict(X_test)\n",
    "    print(\"Testing Accuracy: \", accuracy_score(y_test, y_pred_test))\n",
    "    \n",
    "    y_pred_train = hist.predict(X_train)\n",
    "    print(\"Training Accuracy: \", accuracy_score(y_train, y_pred_train))\n",
    "    print(\"___________________________________________________________________________________________\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
